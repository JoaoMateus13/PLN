{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWg18_OAuYE-"
      },
      "source": [
        "2- Escolha um conjunto de textos  (poemas, letras de música, etc )\n",
        "\n",
        "a) Separe 10% dos textos como conjunto de testes e e o restante como conjunto de treinamento\n",
        "\n",
        "b) Construa um modelo de linguagen  explorando diferentes n-gramas (unigrama, bigrama e trigrama) e métodos de suavização (Laplace vs Lidstone)\n",
        "\n",
        "c) Faça uma análise do melhor modelo de linguagem com base na sua perplexidade no conjunto de teste\n",
        "\n",
        "d) Escolha o melhor modelo e gere um texto de até 30 tokens predizendo a proxima palavra de maxima probabilidade."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WdysnmwrEeG",
        "outputId": "dceaa6dd-a300-4fe8-eee1-f3c12c34201f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\joaom\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\joaom\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import bigrams, trigrams\n",
        "from nltk.lm import MLE, Laplace, Lidstone\n",
        "from nltk.lm.preprocessing import pad_both_ends\n",
        "import re\n",
        "import random\n",
        "import string\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "def pre_processamento(texto):\n",
        "\n",
        "    # seleciona apenas letras e coloca todas em minúsculo\n",
        "    letras_min =  re.findall(r'\\b[A-zÀ-úü]+\\b', texto.lower())\n",
        "\n",
        "    # remove stopwords\n",
        "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "    stop = set(stopwords)\n",
        "    sem_stopwords = [w for w in letras_min if w not in string.punctuation]\n",
        "\n",
        "\n",
        "    # juntando os tokens novamente em formato de texto\n",
        "    texto_limpo = \" \".join(sem_stopwords)\n",
        "\n",
        "    return texto_limpo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RiIa8vDnmnj",
        "outputId": "da697ddb-7ba1-4f77-93b0-6942f431c6ad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package machado to\n",
            "[nltk_data]     C:\\Users\\joaom\\AppData\\Roaming\\nltk_data...\n"
          ]
        }
      ],
      "source": [
        "# id do corpus\n",
        "# no nosso caso estamos usando id machado\n",
        "nltk_id = 'machado'\n",
        "\n",
        "# eh necessario baixar o corpus\n",
        "nltk.download(nltk_id)\n",
        "\n",
        "# agora o corpus esta acessivel\n",
        "# visualizando as obras disponiveis\n",
        "\n",
        "#print(nltk.corpus.machado.readme())\n",
        "# ou\n",
        "\n",
        "#print(nltk.corpus.machado.fileids())\n",
        "\n",
        "# apos escolher a obra\n",
        "# salvamos a string em uma variavel\n",
        "ressurreicao = pre_processamento(nltk.corpus.machado.raw('romance/marm01.txt'))\n",
        "mao_luva = pre_processamento(nltk.corpus.machado.raw('romance/marm02.txt'))\n",
        "helena = pre_processamento(nltk.corpus.machado.raw('romance/marm03.txt'))\n",
        "iaiá_garcia = pre_processamento(nltk.corpus.machado.raw('romance/marm04.txt'))\n",
        "memorias_postumas= pre_processamento(nltk.corpus.machado.raw('romance/marm05.txt'))\n",
        "casa_velha = pre_processamento(nltk.corpus.machado.raw('romance/marm06.txt'))\n",
        "quincas_borba = pre_processamento(nltk.corpus.machado.raw('romance/marm07.txt'))\n",
        "dom_casmurro = pre_processamento(nltk.corpus.machado.raw('romance/marm08.txt'))\n",
        "esau_jaco = pre_processamento(nltk.corpus.machado.raw('romance/marm09.txt'))\n",
        "memorial_aires = pre_processamento(nltk.corpus.machado.raw('romance/marm10.txt'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xFxpCxziN4M"
      },
      "source": [
        "```\n",
        "# 1. paddedLine = [list(pad_both_ends(nltk.word_tokenize(texto), n=2))]\n",
        "# 2. train, vocab = padded_everygram_pipeline(2, paddedLine)\n",
        "# 3. lmMLE = MLE(2)\n",
        "# 4. lmLAP = Laplace(2)\n",
        "# 5. lmLIDS = Lidstone(0.1, 2)\n",
        "# 6. lmMLE.fit(train, vocabulary_text=vocab)\n",
        "# 7. lmLAP.fit(train, vocabulary_text=vocab)\n",
        "# 8. lmLIDS.fit(train, vocabulary_text=vocab)\n",
        "```\n",
        " A linha 1 em questão tokeniza o texto em palavras, adiciona tokens < s> e < /s> de início e fim, criando bigramas apropriados, e coloca o resultado em uma lista.\n",
        "\n",
        "\n",
        " A linha 2 em questão cria o conjunto de treinamento e o vocabulário necessários para treinar o modelo de linguagem com bigramas (n-gramas de tamanho 2)\n",
        "\n",
        "\n",
        " Nas linhas 3,4,5,6 é realizado em sequência a criação dos modelos de linguagens(MLE) de bigramas, modelo de linguagem com suavização Laplace(Laplace(2)) de bigrama e o modelo de linguagem com suavização Lidstone(Lidstone(0.1,2)) (Todos são bigramas)\n",
        "\n",
        "\n",
        "Na linha seguinte é feito o treinamento dos modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "q8LmtL4X0kja"
      },
      "outputs": [],
      "source": [
        "# Exemplo de texto\n",
        "texto = pre_processamento(nltk.corpus.machado.raw('romance/marm01.txt'))\n",
        "\n",
        "indice_90_percent = int(0.9 * len(texto))\n",
        "\n",
        "texto_90_percent = nltk.word_tokenize(texto[:indice_90_percent])\n",
        "texto_10_percent = nltk.word_tokenize(texto[indice_90_percent:])\n",
        "\n",
        "\n",
        "paddedLine = [list(pad_both_ends(texto_90_percent, n=2))]\n",
        "\n",
        "\n",
        "trainMLE, vocabMLE = padded_everygram_pipeline(3, paddedLine)\n",
        "trainLAP, vocabLAP = padded_everygram_pipeline(3, paddedLine)\n",
        "trainLIDS, vocabLIDS = padded_everygram_pipeline(3, paddedLine)\n",
        "\n",
        "lmMLE = MLE(3)\n",
        "lmLAP = Laplace(3)\n",
        "lmLIDS = Lidstone(0.1,3)\n",
        "\n",
        "lmLIDS.fit(trainLIDS, vocabulary_text=vocabLIDS)\n",
        "lmLAP.fit(trainLAP, vocabulary_text=vocabLAP)\n",
        "lmMLE.fit(trainMLE, vocabulary_text=vocabMLE)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FvsI_qkbiwPj"
      },
      "outputs": [],
      "source": [
        "trigramas_test = [list(trigrams(pad_both_ends(texto_10_percent, n=2)))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbDpSQLhn9-s",
        "outputId": "4a5ec2a2-78b1-44f4-cf52-363eb3f35a56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5561.000000000008\n",
            "['que', 'não', 'podia', 'deixar', 'de', 'sorrir', 'só', 'havia', 'uma', 'inexplicável', 'melancolia', 'anterior', 'à', 'sua', 'cabeça', 'angélica', 'não', 'pensava', 'nele', 'o', 'comentário', 'das', 'palavras', 'que', 'houve', 'entre', 'ambas', 'quando', 'a', 'mucama']\n"
          ]
        }
      ],
      "source": [
        "print(lmLIDS.perplexity(trigramas_test))\n",
        "print(lmLIDS.generate(30))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obJuMCrjjKMr",
        "outputId": "bccadb76-6d57-4292-9fb1-ecbf0cf84df5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5561.000000000008\n",
            "['rapariga', 'ao', 'menos', 'parte', 'dele', 'que', 'era', 'ela', 'cansada', 'de', 'esperar', 'que', 'lhe', 'desse', 'tempo', 'o', 'amor', 'nos', 'unisse', 'meneses', 'não', 'estava', 'para', 'estas', 'viagens', 'contínuas', 'e', 'eu', 'sentiria', 'se']\n"
          ]
        }
      ],
      "source": [
        "print(lmLAP.perplexity(trigramas_test))\n",
        "print(lmLAP.generate(30))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiM8cMXajAZO",
        "outputId": "3cecc4c9-0f47-4c89-a3f7-33a7b318f3ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inf\n",
            "['conversa', 'portanto', 'não', 'foi', 'só', 'o', 'que', 'era', 'o', 'desfecho', 'lógico', 'e', 'igual', 'a', 'si', 'próprio', 'a', 'execução', 'seguiu', 'de', 'perto', 'a', 'idéia', 'de', 'que', 'era', 'a', 'transformação', 'de', 'sua']\n"
          ]
        }
      ],
      "source": [
        "print(lmMLE.perplexity(trigramas_test))\n",
        "print(lmMLE.generate(30))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
