{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "2- Escolha um conjunto de textos  (poemas, letras de música, etc )\n",
        "\n",
        "a) Separe 10% dos textos como conjunto de testes e e o restante como conjunto de treinamento\n",
        "\n",
        "b) Construa um modelo de linguagen  explorando diferentes n-gramas (unigrama, bigrama e trigrama) e métodos de suavização (Laplace vs Lidstone)\n",
        "\n",
        "c) Faça uma análise do melhor modelo de linguagem com base na sua perplexidade no conjunto de teste\n",
        "\n",
        "d) Escolha o melhor modelo e gere um texto de até 30 tokens predizendo a proxima palavra de maxima probabilidade."
      ],
      "metadata": {
        "id": "lWg18_OAuYE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import bigrams, trigrams\n",
        "from nltk.lm import MLE, Laplace, Lidstone\n",
        "from nltk.lm.preprocessing import pad_both_ends\n",
        "import re\n",
        "import random\n",
        "import string\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "def pre_processamento(texto):\n",
        "\n",
        "    # seleciona apenas letras e coloca todas em minúsculo\n",
        "    letras_min =  re.findall(r'\\b[A-zÀ-úü]+\\b', texto.lower())\n",
        "\n",
        "    # remove stopwords\n",
        "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "    stop = set(stopwords)\n",
        "    sem_stopwords = [w for w in letras_min if w not in string.punctuation]\n",
        "\n",
        "\n",
        "    # juntando os tokens novamente em formato de texto\n",
        "    texto_limpo = \" \".join(sem_stopwords)\n",
        "\n",
        "    return texto_limpo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WdysnmwrEeG",
        "outputId": "dceaa6dd-a300-4fe8-eee1-f3c12c34201f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RiIa8vDnmnj",
        "outputId": "da697ddb-7ba1-4f77-93b0-6942f431c6ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]   Package machado is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# id do corpus\n",
        "# no nosso caso estamos usando id machado\n",
        "nltk_id = 'machado'\n",
        "\n",
        "# eh necessario baixar o corpus\n",
        "nltk.download(nltk_id)\n",
        "\n",
        "# agora o corpus esta acessivel\n",
        "# visualizando as obras disponiveis\n",
        "\n",
        "#print(nltk.corpus.machado.readme())\n",
        "# ou\n",
        "\n",
        "#print(nltk.corpus.machado.fileids())\n",
        "\n",
        "# apos escolher a obra\n",
        "# salvamos a string em uma variavel\n",
        "ressurreicao = pre_processamento(nltk.corpus.machado.raw('romance/marm01.txt'))\n",
        "mao_luva = pre_processamento(nltk.corpus.machado.raw('romance/marm02.txt'))\n",
        "helena = pre_processamento(nltk.corpus.machado.raw('romance/marm03.txt'))\n",
        "iaiá_garcia = pre_processamento(nltk.corpus.machado.raw('romance/marm04.txt'))\n",
        "memorias_postumas= pre_processamento(nltk.corpus.machado.raw('romance/marm05.txt'))\n",
        "casa_velha = pre_processamento(nltk.corpus.machado.raw('romance/marm06.txt'))\n",
        "quincas_borba = pre_processamento(nltk.corpus.machado.raw('romance/marm07.txt'))\n",
        "dom_casmurro = pre_processamento(nltk.corpus.machado.raw('romance/marm08.txt'))\n",
        "esau_jaco = pre_processamento(nltk.corpus.machado.raw('romance/marm09.txt'))\n",
        "memorial_aires = pre_processamento(nltk.corpus.machado.raw('romance/marm10.txt'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "textos = [ressurreicao, mao_luva, helena,iaiá_garcia, memorias_postumas, casa_velha,\n",
        "          quincas_borba, dom_casmurro, esau_jaco, memorial_aires]\n",
        "\n",
        "tamanho_treinamento = int(len(textos) * 0.9)\n",
        "tamanho_teste = len(textos) - tamanho_treinamento\n",
        "\n",
        "random.shuffle(textos)\n",
        "\n",
        "conjunto_treinamento = textos[:tamanho_treinamento]\n",
        "conjunto_teste = textos[tamanho_treinamento:]\n",
        "\"\"\"\n",
        "print(\"Conjunto de Treinamento:\")\n",
        "for texto in conjunto_treinamento:\n",
        "    print(texto)\n",
        "\n",
        "print(\"\\nConjunto de Teste:\")\n",
        "for texto in conjunto_teste:\n",
        "    print(texto)\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jmt5rUElrofX",
        "outputId": "4f862e41-a22d-49b4-b6a3-d85424a8d2ec"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprint(\"Conjunto de Treinamento:\")\\nfor texto in conjunto_treinamento:\\n    print(texto)\\n\\nprint(\"\\nConjunto de Teste:\")\\nfor texto in conjunto_teste:\\n    print(texto)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "# 1. paddedLine = [list(pad_both_ends(nltk.word_tokenize(texto), n=2))]\n",
        "# 2. train, vocab = padded_everygram_pipeline(2, paddedLine)\n",
        "# 3. lmMLE = MLE(2)\n",
        "# 4. lmLAP = Laplace(2)\n",
        "# 5. lmLIDS = Lidstone(0.1, 2)\n",
        "# 6. lmMLE.fit(train, vocabulary_text=vocab)\n",
        "# 7. lmLAP.fit(train, vocabulary_text=vocab)\n",
        "# 8. lmLIDS.fit(train, vocabulary_text=vocab)\n",
        "```\n",
        " A linha 1 em questão tokeniza o texto em palavras, adiciona tokens < s> e < /s> de início e fim, criando bigramas apropriados, e coloca o resultado em uma lista.\n",
        "\n",
        "\n",
        " A linha 2 em questão cria o conjunto de treinamento e o vocabulário necessários para treinar o modelo de linguagem com bigramas (n-gramas de tamanho 2)\n",
        "\n",
        "\n",
        " Nas linhas 3,4,5,6 é realizado em sequência a criação dos modelos de linguagens(MLE) de bigramas, modelo de linguagem com suavização Laplace(Laplace(2)) de bigrama e o modelo de linguagem com suavização Lidstone(Lidstone(0.1,2)) (Todos são bigramas)\n",
        "\n",
        "\n",
        "Na linha seguinte é feito o treinamento dos modelos."
      ],
      "metadata": {
        "id": "4xFxpCxziN4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de texto\n",
        "texto = pre_processamento(nltk.corpus.machado.raw('romance/marm01.txt'))\n",
        "\n",
        "indice_90_percent = int(0.9 * len(texto))\n",
        "\n",
        "texto_90_percent = nltk.word_tokenize(texto[:indice_90_percent])\n",
        "texto_10_percent = nltk.word_tokenize(texto[indice_90_percent:])\n",
        "\n",
        "\n",
        "paddedLine = [list(pad_both_ends(texto_90_percent, n=2))]\n",
        "\n",
        "\n",
        "trainMLE, vocabMLE = padded_everygram_pipeline(3, paddedLine)\n",
        "trainLAP, vocabLAP = padded_everygram_pipeline(3, paddedLine)\n",
        "trainLIDS, vocabLIDS = padded_everygram_pipeline(3, paddedLine)\n",
        "\n",
        "lmMLE = MLE(3)\n",
        "lmLAP = Laplace(3)\n",
        "lmLIDS = Lidstone(0.1,3)\n",
        "\n",
        "lmLIDS.fit(trainLIDS, vocabulary_text=vocabLIDS)\n",
        "lmLAP.fit(trainLAP, vocabulary_text=vocabLAP)\n",
        "lmMLE.fit(trainMLE, vocabulary_text=vocabMLE)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "q8LmtL4X0kja"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trigramas_test = [list(trigrams(pad_both_ends(texto_10_percent, n=2)))]"
      ],
      "metadata": {
        "id": "FvsI_qkbiwPj"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lmLIDS.perplexity(trigramas_test))\n",
        "print(lmLIDS.generate(30))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbDpSQLhn9-s",
        "outputId": "4a5ec2a2-78b1-44f4-cf52-363eb3f35a56"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5561.000000000008\n",
            "['félix', 'tanto', 'mais', 'disse', 'ele', 'há', 'muito', 'tempo', 'mais', 'meteu', 'se', 'nele', 'e', 'mandou', 'chamar', 'o', 'médico', 'e', 'dirigiu', 'se', 'para', 'o', 'médico', 'era', 'impossível', 'entretanto', 'não', 'era', 'assim', 'aparentemente']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lmLAP.perplexity(trigramas_test))\n",
        "print(lmLAP.generate(30))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obJuMCrjjKMr",
        "outputId": "bccadb76-6d57-4292-9fb1-ecbf0cf84df5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5561.000000000008\n",
            "['da', 'janela', 'com', 'o', 'tempo', 'há', 'amigos', 'de', 'meu', 'irmão', 'falava', 'dele', 'com', 'os', 'derradeiros', 'lampejos', 'do', 'crepúsculo', 'até', 'que', 'perderia', 'eu', 'com', 'isso', 'a', 'que', 'ela', 'pretendia', 'fazer', 'caminhavam']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lmMLE.perplexity(trigramas_test))\n",
        "print(lmMLE.generate(30))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiM8cMXajAZO",
        "outputId": "3cecc4c9-0f47-4c89-a3f7-33a7b318f3ff"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inf\n",
            "['tínhamos', 'veio', 'tirar', 'no', 'la', 'o', 'assunto', 'no', 'chão', 'posso', 'ir', 'à', 'chácara', 'podes', 'leva', 'o', 'clara', 'luís', 'deitou', 'a', 'correr', 'as', 'lágrimas', 'choradas', 'durante', 'aqueles', 'oito', 'dias', 'e', 'indiferentes']\n"
          ]
        }
      ]
    }
  ]
}